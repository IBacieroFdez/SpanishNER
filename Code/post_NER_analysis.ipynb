{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuando vamos a analizar un texto.\n",
    "\n",
    "Para imprimir tokens junto con sus anotaciones:\n",
    "    print([(word, word.ent_type_) for word in sentence_nlp if word.ent_type_])\n",
    "    \n",
    "    \n",
    "    from spacy import displacy\n",
    "\n",
    "Para ver las dependencias entre tokens (POS):\n",
    "\n",
    "    displacy.render(sentence_nlp, jupyter=True, \n",
    "                    options={'distance': 110,\n",
    "                             'arrow_stroke': 2,\n",
    "                             'arrow_width': 8})\n",
    "\n",
    "Para imprimirlo en el texto y subrayado:\n",
    "                \n",
    "    displacy.render(sentence_nlp, style='ent', jupyter=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar a hacer metricas del texto que estamos analizando:\n",
    "    Mete en el dataframe cada palabra y la frecuencia con la que es utilizada\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('/Users/ignaciobacierofernandez/Desktop/TFG/NLP/Modelos/it_1')\n",
    "for text, _ in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "        #print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "        #print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "        displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "        \n",
    "        #A partir de aqui, creamos un dataframe en el que metemos cada palabra identificada con su etiqueta correspondiente \n",
    "named_entities = []\n",
    "for sentence in corpus:\n",
    "    temp_entity_name = ''\n",
    "    temp_named_entity = None\n",
    "    sentence = nlp(sentence)\n",
    "    for word in sentence:\n",
    "        term = word.text \n",
    "        tag = word.ent_type_\n",
    "        if tag:\n",
    "            temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "            temp_named_entity = (temp_entity_name, tag)\n",
    "        else:\n",
    "            if temp_named_entity:\n",
    "                named_entities.append(temp_named_entity)\n",
    "                temp_entity_name = ''\n",
    "                temp_named_entity = None\n",
    "\n",
    "entity_frame = pd.DataFrame(named_entities, \n",
    "                            columns=['Entity Name', 'Entity Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra las 15 palabras mas repetidas del texto que estamos analizando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_entities = (entity_frame.groupby(by=['Entity Name', 'Entity Type'])\n",
    "                           .size()\n",
    "                           .sort_values(ascending=False)\n",
    "                           .reset_index().rename(columns={0 : 'Frequency'}))\n",
    "top_entities.T.iloc[:,:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
